{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Workspace problem with several narrow gaps\n",
      "\n",
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.patches as patches\n",
      "import matplotlib.gridspec as gridspec\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "import os\n",
      "import csv\n",
      "from random import randint, random\n",
      "import time\n",
      "\n",
      "# (restrict tensorflow memory growth)\n",
      "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
      "config = tf.ConfigProto()\n",
      "config.gpu_options.allow_growth=True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# neural network parameters\n",
      "mb_size = 256\n",
      "h_Q_dim = 512\n",
      "h_P_dim = 512\n",
      "\n",
      "c = 0\n",
      "# learning rate\n",
      "lr = 1e-4\n",
      "\n",
      "# problem dimensions\n",
      "dim = 7\n",
      "dataElements = dim*3 + 32 # sample (7D), init (7D), goal (7D), cond (16+16 points (table + box)) //total = 37\n",
      "\n",
      "z_dim = 4 # latent\n",
      "X_dim = dim # samples\n",
      "y_dim = dim # reconstruction of the original point\n",
      "c_dim = dataElements - dim # dimension of conditioning variable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read in data from csv\n",
      "filename = 'samplingdata.txt'\n",
      "f = open(filename, 'rb')\n",
      "reader = csv.reader(f, delimiter=',')\n",
      "count = 0\n",
      "data_list = []\n",
      "for row in reader:\n",
      "    data_list.append(map(float,row[0:dataElements]))\n",
      "\n",
      "data = np.array(data_list,dtype='d')\n",
      "\n",
      "######################### Comment it #############\n",
      "# data[:,3:6] = 0\n",
      "##################################################\n",
      "print(\"shape of array: \",data.shape)\n",
      "\n",
      "numEntries = data.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('shape of array: ', (12716, 53))\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# split the inputs and conditions into test train (to be processed in the next step into an occupancy grid representation)\n",
      "ratioTestTrain = 0.99;\n",
      "numTrain = int(numEntries*ratioTestTrain)\n",
      "\n",
      "X_train = data[0:numTrain,0:dim] # state: x, y, z, xdot, ydot, zdot\n",
      "c_train = data[0:numTrain,dim:dataElements] # conditions: gaps, init (6), goal (6)\n",
      "\n",
      "X_test = data[numTrain:numEntries,0:dim]\n",
      "c_test = data[numTrain:numEntries,dim:dataElements]\n",
      "\n",
      "#########################################################\n",
      "c_train1 = []\n",
      "c_test1 = []\n",
      "c_train1 = c_train\n",
      "c_test1 = c_test\n",
      "#########################################################\n",
      "numTest = X_test.shape[0]\n",
      "\n",
      "# print(\"shape of final obstacle = \",obs.shape)\n",
      "print(\"shape of c_train1 = \", c_train1.shape)\n",
      "print(\"shape of c_test1 = \",c_test1.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('shape of c_train1 = ', (12588, 46))\n",
        "('shape of c_test1 = ', (128, 46))\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define networks\n",
      "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
      "c = tf.placeholder(tf.float32, shape=[None, c_dim])\n",
      "\n",
      "# Q\n",
      "inputs_Q = tf.concat(axis=1, values=[X,c])\n",
      "\n",
      "dense_Q1 = tf.layers.dense(inputs=inputs_Q, units=h_Q_dim, activation=tf.nn.relu)\n",
      "dropout_Q1 = tf.layers.dropout(inputs=dense_Q1, rate=0.5)\n",
      "dense_Q2 = tf.layers.dense(inputs=dropout_Q1, units=h_Q_dim, activation=tf.nn.relu)\n",
      "\n",
      "z_mu = tf.layers.dense(inputs=dense_Q2, units=z_dim) # output here is z_mu\n",
      "z_logvar = tf.layers.dense(inputs=dense_Q2, units=z_dim) # output here is z_logvar\n",
      "\n",
      "# P\n",
      "eps = tf.random_normal(shape=tf.shape(z_mu))\n",
      "z = z_mu + tf.exp(z_logvar / 2) * eps\n",
      "inputs_P = tf.concat(axis=1, values=[z,c])\n",
      "\n",
      "dense_P1 = tf.layers.dense(inputs=inputs_P, units=h_P_dim, activation=tf.nn.relu)\n",
      "dropout_P1 = tf.layers.dropout(inputs=dense_P1, rate=0.5)\n",
      "dense_P2 = tf.layers.dense(inputs=dropout_P1, units=h_P_dim, activation=tf.nn.relu)\n",
      "\n",
      "y = tf.layers.dense(inputs=dense_P2, units=X_dim) # fix to also output y\n",
      "\n",
      "# training\n",
      "########### comment in the one with 0 weight and uncomment the other ###########\n",
      "w = [[1, 1, 1, 1, 1, 1, 1]];\n",
      "# w = [[1, 1, 1, 0, 0, 0]];\n",
      "recon_loss = tf.losses.mean_squared_error(labels=X, predictions=y, weights=w)\n",
      "\n",
      "# TODO: fix loss function for angles going around\n",
      "kl_loss = 10**-4 * 2 * tf.reduce_sum(tf.exp(z_logvar) + z_mu**2 - 1. - z_logvar, 1)\n",
      "\n",
      "cvae_loss = tf.reduce_mean(kl_loss + recon_loss)\n",
      "\n",
      "train_step = tf.train.AdamOptimizer(lr).minimize(cvae_loss)\n",
      "\n",
      "sess = tf.Session(config=config)\n",
      "sess.run(tf.global_variables_initializer())\n",
      "it = 0;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "saver = tf.train.Saver()\n",
      "path_ = os.getcwd() + \"/checkpoints_z4/model.ckpt\"\n",
      "print(\"path = \",path_)\n",
      "print(\"numTrain = \",numTrain)\n",
      "try:\n",
      "    saver.restore(sess, path_)\n",
      "    print(\"Model Restored!!\")\n",
      "except Exception as e:\n",
      "    print(\"Could not restore checkpoint!\")\n",
      "    print(e)\n",
      "x1 = []\n",
      "y1 = []    \n",
      "for it in range(it,it+500001):\n",
      "    # randomly generate batches\n",
      "    batch_elements = [randint(0,numTrain-1) for n in range(0,mb_size)]\n",
      "    X_mb = X_train[batch_elements,:]\n",
      "    c_mb = c_train1[batch_elements,:]\n",
      "\n",
      "    _, loss = sess.run([train_step, cvae_loss], feed_dict={X: X_mb, c: c_mb})\n",
      "\n",
      "    if it % 1000 == 0:\n",
      "        print('Iter: {}'.format(it))\n",
      "        print('Loss: {:.4}'. format(loss))\n",
      "        x1.append(it)\n",
      "        y1.append(loss)\n",
      "        saver.save(sess, path_)\n",
      "        print(\"saved session to \", path_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('path = ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z4/model.ckpt')\n",
        "('numTrain = ', 12588)\n",
        "Model Restored!!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 48000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.03351\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z4/model.ckpt')"
       ]
      }
     ],
     "prompt_number": "*"
    }
   ],
   "metadata": {}
  }
 ]
}