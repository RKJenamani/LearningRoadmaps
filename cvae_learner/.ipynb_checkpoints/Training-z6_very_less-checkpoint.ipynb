{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import openravepy\n",
      "import rospy\n",
      "import os\n",
      "import herbpy\n",
      "from prpy import serialization\n",
      "\n",
      "env, robot = herbpy.initialize(sim=True, attach_viewer='interactivemarker')\n",
      "\n",
      "from catkin.find_in_workspaces import find_in_workspaces\n",
      "\n",
      "package_name = 'pr_ordata'\n",
      "directory = 'data'\n",
      "objects_path = find_in_workspaces(\n",
      "    search_dirs=['share'],\n",
      "    project=package_name,\n",
      "    path=directory,\n",
      "    first_match_only=True)\n",
      "if len(objects_path) == 0:\n",
      "    print('Can\\'t find directory %s/%s' % (package_name, directory))\n",
      "    sys.exit()\n",
      "else:\n",
      "    print objects_path # for me this is '/home/USERNAME/catkin_workspaces/herb_ws/src/pr-ordata/data/objects'\n",
      "    objects_path = objects_path[0]\n",
      "    \n",
      "robot.right_arm.SetActive()\n",
      "# Load table from pr_ordata\n",
      "table_file = os.path.join(objects_path,'objects/table.kinbody.xml')\n",
      "tall_white_box_file = os.path.join(objects_path,'objects/tall_white_box.kinbody.xml')\n",
      "table = env.ReadKinBodyXMLFile(table_file)\n",
      "env.AddKinBody(table)\n",
      "tall_white_box = env.ReadKinBodyXMLFile(tall_white_box_file)\n",
      "env.AddKinBody(tall_white_box)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Workspace problem with several narrow gaps\n",
      "\n",
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.patches as patches\n",
      "import matplotlib.gridspec as gridspec\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "import os\n",
      "import csv\n",
      "from random import randint, random\n",
      "import time\n",
      "\n",
      "# (restrict tensorflow memory growth)\n",
      "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
      "config = tf.ConfigProto()\n",
      "config.gpu_options.allow_growth=True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# neural network parameters\n",
      "mb_size = 256\n",
      "h_Q_dim = 512\n",
      "h_P_dim = 512\n",
      "\n",
      "c = 0\n",
      "# learning rate\n",
      "lr = 1e-4\n",
      "\n",
      "# problem dimensions\n",
      "dim = 7\n",
      "dataElements = dim*3 + 32 # sample (7D), init (7D), goal (7D), cond (16+16 points (table + box)) //total = 37\n",
      "\n",
      "z_dim = 6 # latent\n",
      "X_dim = dim # samples\n",
      "y_dim = dim # reconstruction of the original point\n",
      "c_dim = dataElements - dim # dimension of conditioning variable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read in data from csv\n",
      "filename = 'samplingdata.txt'\n",
      "f = open(filename, 'rb')\n",
      "reader = csv.reader(f, delimiter=',')\n",
      "count = 0\n",
      "data_list = []\n",
      "for row in reader:\n",
      "    data_list.append(map(float,row[0:dataElements]))\n",
      "\n",
      "data = np.array(data_list,dtype='d')\n",
      "\n",
      "######################### Comment it #############\n",
      "# data[:,3:6] = 0\n",
      "##################################################\n",
      "print(\"shape of array: \",data.shape)\n",
      "\n",
      "numEntries = data.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('shape of array: ', (12716, 53))\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# split the inputs and conditions into test train (to be processed in the next step into an occupancy grid representation)\n",
      "ratioTestTrain = 0.1;\n",
      "numTrain = int(numEntries*ratioTestTrain)\n",
      "\n",
      "X_train = data[0:numTrain,0:dim] # state: x, y, z, xdot, ydot, zdot\n",
      "c_train = data[0:numTrain,dim:dataElements] # conditions: gaps, init (6), goal (6)\n",
      "\n",
      "X_test = data[numTrain:numEntries,0:dim]\n",
      "c_test = data[numTrain:numEntries,dim:dataElements]\n",
      "\n",
      "#########################################################\n",
      "c_train1 = []\n",
      "c_test1 = []\n",
      "c_train1 = c_train\n",
      "c_test1 = c_test\n",
      "#########################################################\n",
      "numTest = X_test.shape[0]\n",
      "\n",
      "# print(\"shape of final obstacle = \",obs.shape)\n",
      "print(\"shape of c_train1 = \", c_train1.shape)\n",
      "print(\"shape of c_test1 = \",c_test1.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('shape of c_train1 = ', (1271, 46))\n",
        "('shape of c_test1 = ', (11445, 46))\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define networks\n",
      "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
      "c = tf.placeholder(tf.float32, shape=[None, c_dim])\n",
      "\n",
      "# Q\n",
      "inputs_Q = tf.concat(axis=1, values=[X,c])\n",
      "\n",
      "dense_Q1 = tf.layers.dense(inputs=inputs_Q, units=h_Q_dim, activation=tf.nn.relu)\n",
      "dropout_Q1 = tf.layers.dropout(inputs=dense_Q1, rate=0.5)\n",
      "dense_Q2 = tf.layers.dense(inputs=dropout_Q1, units=h_Q_dim, activation=tf.nn.relu)\n",
      "\n",
      "z_mu = tf.layers.dense(inputs=dense_Q2, units=z_dim) # output here is z_mu\n",
      "z_logvar = tf.layers.dense(inputs=dense_Q2, units=z_dim) # output here is z_logvar\n",
      "\n",
      "# P\n",
      "eps = tf.random_normal(shape=tf.shape(z_mu))\n",
      "z = z_mu + tf.exp(z_logvar / 2) * eps\n",
      "# z_sigma = tf.exp(z_logvar /2)\n",
      "inputs_P = tf.concat(axis=1, values=[z,c])\n",
      "\n",
      "dense_P1 = tf.layers.dense(inputs=inputs_P, units=h_P_dim, activation=tf.nn.relu)\n",
      "dropout_P1 = tf.layers.dropout(inputs=dense_P1, rate=0.5)\n",
      "dense_P2 = tf.layers.dense(inputs=dropout_P1, units=h_P_dim, activation=tf.nn.relu)\n",
      "\n",
      "y = tf.layers.dense(inputs=dense_P2, units=X_dim) # fix to also output y\n",
      "\n",
      "# training\n",
      "########### comment in the one with 0 weight and uncomment the other ###########\n",
      "w = [[1, 1, 1, 1, 1, 1, 1]];\n",
      "# w = [[1, 1, 1, 0, 0, 0]];\n",
      "recon_loss = tf.losses.mean_squared_error(labels=X, predictions=y, weights=w)\n",
      "\n",
      "# TODO: fix loss function for angles going around\n",
      "kl_loss = 10**-4 * 2 * tf.reduce_sum(tf.exp(z_logvar) + z_mu**2 - 1. - z_logvar, 1)\n",
      "\n",
      "cvae_loss = tf.reduce_mean(kl_loss + recon_loss)\n",
      "\n",
      "train_step = tf.train.AdamOptimizer(lr).minimize(cvae_loss)\n",
      "\n",
      "sess = tf.Session(config=config)\n",
      "sess.run(tf.global_variables_initializer())\n",
      "it = 0;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "saver = tf.train.Saver()\n",
      "path_ = os.getcwd() + \"/checkpoints_z6_11Junedata_very_less/model.ckpt\"\n",
      "print(\"path = \",path_)\n",
      "print(\"numTrain = \",numTrain)\n",
      "try:\n",
      "    saver.restore(sess, path_)\n",
      "    print(\"Model Restored!!\")\n",
      "except Exception as e:\n",
      "    print(\"Could not restore checkpoint!\")\n",
      "    print(e)\n",
      "x1 = []\n",
      "y1 = []    \n",
      "mu = []\n",
      "sigma = []\n",
      "n_ = []\n",
      "for it in range(it,it+500001):\n",
      "    # randomly generate batches\n",
      "    batch_elements = [randint(0,numTrain-1) for n in range(0,mb_size)]\n",
      "    X_mb = X_train[batch_elements,:]\n",
      "    c_mb = c_train1[batch_elements,:]\n",
      "    \n",
      "    _, loss, r = sess.run([train_step, cvae_loss, recon_loss], feed_dict={X: X_mb, c: c_mb})\n",
      "\n",
      "#     _, loss, m, s = sess.run([train_step, cvae_loss, z_mu, z_sigma], feed_dict={X: X_mb, c: c_mb})\n",
      "\n",
      "    if it % 1000 == 0:\n",
      "        print('Iter: {}'.format(it))\n",
      "        print('Loss: {:.4}'. format(loss))\n",
      "        print('Recon_loss: {:.6}'.format(r))\n",
      "        print('kl_loss = ', loss-r)\n",
      "#         mu.append(m)\n",
      "#         sigma.append(s)\n",
      "        n_.append(it)\n",
      "        saver.save(sess, path_)\n",
      "        print(\"saved session to \", path_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('path = ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_very_less/model.ckpt')\n",
        "('numTrain = ', 1271)\n",
        "Model Restored!!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 3.296\n",
        "Recon_loss: 3.29608\n",
        "('kl_loss = ', 0.00025129318)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_very_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.0406\n",
        "Recon_loss: 0.029272\n",
        "('kl_loss = ', 0.01133047)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_very_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 2000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.02328\n",
        "Recon_loss: 0.012611\n",
        "('kl_loss = ', 0.010664418)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_very_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 3000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.01773\n",
        "Recon_loss: 0.00730434\n",
        "('kl_loss = ', 0.010422112)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_very_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 4000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.01508\n",
        "Recon_loss: 0.00520851\n",
        "('kl_loss = ', 0.009867206)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_very_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 5000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.01311\n",
        "Recon_loss: 0.00372038\n",
        "('kl_loss = ', 0.009389775)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_very_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 6000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.01218\n",
        "Recon_loss: 0.0028086\n",
        "('kl_loss = ', 0.009372028)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_very_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 7000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.01195\n",
        "Recon_loss: 0.00277293\n",
        "('kl_loss = ', 0.009177485)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_very_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 8000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.01138\n",
        "Recon_loss: 0.00234251\n",
        "('kl_loss = ', 0.0090378625)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_very_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 9000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.01091\n",
        "Recon_loss: 0.00199981\n",
        "('kl_loss = ', 0.008908644)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_very_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 10000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.01081\n",
        "Recon_loss: 0.00200882\n",
        "('kl_loss = ', 0.008801203)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_very_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 11000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.01102\n",
        "Recon_loss: 0.00218698\n",
        "('kl_loss = ', 0.008831469)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_very_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 12000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.01027\n",
        "Recon_loss: 0.00166244\n",
        "('kl_loss = ', 0.008608433)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_very_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 13000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.01039\n",
        "Recon_loss: 0.00175928\n",
        "('kl_loss = ', 0.008627514)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_very_less/model.ckpt')"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(c,z)\n",
      "def create_samples(G, directory):\n",
      "    start = np.loadtxt(directory+\"/start_node.txt\")\n",
      "    goal = np.loadtxt(directory+\"/goal_node.txt\")\n",
      "    cond = np.loadtxt(directory+\"/conditions.txt\")\n",
      "#     cond = np.array([cond[23]])\n",
      "    def state_to_numpy(state):\n",
      "        strlist = state.split()\n",
      "        val_list = [float(s) for s in strlist]\n",
      "        return np.array(val_list)\n",
      "    \n",
      "    # cond = cond.split(\",\")\n",
      "    path_nodes = []\n",
      "    i = 0\n",
      "    c_samples = []\n",
      "    with open(directory + \"/path_nodes.txt\", 'r') as file:\n",
      "        lines  = file.readlines()\n",
      "        for line in lines:\n",
      "            line = line.strip('\\n')\n",
      "#             print(line)\n",
      "#             print(\"\\n\\n\")\n",
      "            if(not line == '-1'):\n",
      "                s = state_to_numpy(G.node[str(int(start[i]))]['state'])\n",
      "                g = state_to_numpy(G.node[str(int(goal[i]))]['state'])\n",
      "                path_nodes = str(line).split(\",\")\n",
      "                # print(path_nodes)\n",
      "                for path_node in path_nodes:\n",
      "                    node_conf = state_to_numpy(G.node[path_node]['state'])\n",
      "                    curr_node = np.array([])\n",
      "                    # print(\"Data = \",node_conf, s, g, cond)\n",
      "#                     print(\"\\n\")\n",
      "                    curr_node = np.concatenate((s, g, cond))\n",
      "                    c_samples.append(curr_node)\n",
      "    return np.array(c_samples)\n",
      "print(\"c, z = \",c, z)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(<tf.Tensor 'Placeholder_5:0' shape=(?, 46) dtype=float32>, <tf.Tensor 'add_6:0' shape=(?, 6) dtype=float32>)\n",
        "('c, z = ', <tf.Tensor 'Placeholder_5:0' shape=(?, 46) dtype=float32>, <tf.Tensor 'add_6:0' shape=(?, 6) dtype=float32>)\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_v = [200, 300, 400, 500]\n",
      "c_final = []\n",
      "print(\"c, z = \", c, z)\n",
      "import networkx as nx\n",
      "from random import choice\n",
      "G = nx.read_graphml(\"graphs/modified_graph_30000.graphml\")\n",
      "\n",
      "dire = [\"test_data_11June/T1/4\", \"test_data_11June/T1/7\", \"test_data_11June/T2/0\", \"test_data_11June/T2/4\", \"test_data_11June/T2/7\", \"test_data_11June/T2/14\"]\n",
      "dire = [\"temp_data/T2/5\", \"temp_data/T1/5\"]\n",
      "for num_viz in num_v:\n",
      "    for directory in dire:\n",
      "        c_final = []\n",
      "        c_samples = np.float32(create_samples(G, directory))\n",
      "    \n",
      "        for i in range(num_viz):\n",
      "            c_final.append(choice(c_samples))\n",
      "        z_final = np.random.randn(num_viz,z_dim)\n",
      "    \n",
      "        c_final = np.array(c_final)\n",
      "        print(\"c_final_dim = \",c_final.shape)\n",
      "        print(\"z_dim = \",z_final.shape)\n",
      "        # directly sample from the latent space (preferred, what we will use in the end)\n",
      "        y_viz, z_viz = sess.run([y, z], feed_dict={z: z_final, c: c_final})\n",
      "    \n",
      "        print(y_viz)\n",
      "        np.savetxt(directory+\"/output_samples_z\"+str(z_dim)+\"_n\"+str(num_viz)+\".txt\", y_viz, delimiter=\" \", fmt=\"%s\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('c, z = ', <tf.Tensor 'Placeholder_5:0' shape=(?, 46) dtype=float32>, <tf.Tensor 'add_6:0' shape=(?, 6) dtype=float32>)\n",
        "('c_final_dim = ', (200, 46))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('z_dim = ', (200, 6))\n",
        "[[ 2.4236362  -1.2201136  -0.17813624 ... -1.1166337  -0.49523193\n",
        "   0.4949282 ]\n",
        " [ 3.7645245  -0.77706456  0.04318722 ... -2.000904    0.1467629\n",
        "   1.3983527 ]\n",
        " [ 3.4948316  -1.2122506   1.022992   ... -3.2633986   0.7758813\n",
        "  -0.89928913]\n",
        " ...\n",
        " [ 3.855482   -1.3486737   1.0211886  ...  0.4819937   1.444848\n",
        "   1.9030457 ]\n",
        " [ 3.4332426  -1.5450472  -0.02372788 ... -0.8524125   0.04960955\n",
        "   0.01323025]\n",
        " [ 2.0676954  -0.9491413  -0.42945722 ... -2.551875   -0.6829947\n",
        "   0.14782609]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('c_final_dim = ', (200, 46))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('z_dim = ', (200, 6))\n",
        "[[ 2.1028662e+00  2.8114223e-01 -1.8630166e-01 ... -2.4710884e-03\n",
        "  -1.4373819e+00  2.4042530e+00]\n",
        " [ 1.9067364e+00 -4.0845212e-02  1.5191796e-01 ... -1.9060853e+00\n",
        "   6.8787616e-01  2.6252022e+00]\n",
        " [ 5.0536613e+00 -3.4760034e-01 -1.3856262e+00 ... -2.4439893e+00\n",
        "   2.5729871e-01  1.8942933e+00]\n",
        " ...\n",
        " [ 1.9963112e+00  3.4034631e-01 -1.3083529e+00 ... -1.0165855e+00\n",
        "   1.2668632e-02 -5.8429682e-01]\n",
        " [ 4.5407457e+00 -8.1475687e-01 -1.1405032e+00 ... -1.6605756e+00\n",
        "   1.3519351e+00  9.2724755e-02]\n",
        " [ 3.0932415e+00  1.9476390e-01 -1.1672838e+00 ... -6.6594821e-01\n",
        "   2.6125103e-01  2.5940084e+00]]\n",
        "('c_final_dim = ', (300, 46))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('z_dim = ', (300, 6))\n",
        "[[ 2.7204344  -1.1786958   1.8630798  ... -0.20457357  0.6182101\n",
        "  -0.20564789]\n",
        " [ 4.2161655  -0.5498841   0.9642721  ... -0.33343098 -0.5346811\n",
        "   0.32410476]\n",
        " [ 3.0867894  -0.90220875 -1.56068    ... -2.204617   -0.3668607\n",
        "  -1.546195  ]\n",
        " ...\n",
        " [ 3.907557   -1.4130424  -2.073353   ... -1.8523167  -0.34349906\n",
        "   0.7742752 ]\n",
        " [ 3.1436098  -1.526664   -0.7284701  ... -0.0701091   0.8202952\n",
        "  -0.18884946]\n",
        " [ 4.260558   -0.96837455  0.9938201  ... -1.6573856   0.45362845\n",
        "  -1.7452097 ]]\n",
        "('c_final_dim = ', (300, 46))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('z_dim = ', (300, 6))\n",
        "[[ 3.9646187   0.22681636  0.6465513  ... -1.083654    0.31108874\n",
        "   0.33280158]\n",
        " [ 2.802263    1.5924355  -0.48429352 ... -1.8812907  -0.19949849\n",
        "   0.01662871]\n",
        " [ 1.127683   -0.76439995 -0.4585862  ... -1.774669   -0.1958202\n",
        "   1.9907902 ]\n",
        " ...\n",
        " [ 3.5649703  -0.79014444 -1.0312921  ... -0.88375294 -0.19798292\n",
        "   1.2631755 ]\n",
        " [ 2.2935452   0.6025808  -0.8092295  ...  0.50027907  0.17963144\n",
        "   0.8661046 ]\n",
        " [ 1.2412996  -0.52924806 -0.718667   ... -0.76104206  0.06327856\n",
        "  -0.73263365]]\n",
        "('c_final_dim = ', (400, 46))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('z_dim = ', (400, 6))\n",
        "[[ 3.776902   -0.6098735   0.879567   ... -2.1215568  -0.05627681\n",
        "   1.2549158 ]\n",
        " [ 2.3251593  -1.0152806  -1.0434841  ... -0.04263222 -0.11638712\n",
        "  -0.37083986]\n",
        " [ 3.293111   -1.142633   -0.37769893 ... -1.2484235   0.98373353\n",
        "   0.40277037]\n",
        " ...\n",
        " [ 3.5979502  -0.97564274 -0.2695787  ... -2.0310683   0.974989\n",
        "   0.905896  ]\n",
        " [ 3.2633522  -1.3818417  -1.2156831  ... -0.85368955  0.70602405\n",
        "   0.45416018]\n",
        " [ 3.6150892  -1.3691931   0.5158482  ... -3.612246    1.3259668\n",
        "   1.8446667 ]]\n",
        "('c_final_dim = ', (400, 46))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('z_dim = ', (400, 6))\n",
        "[[ 4.3383594  -0.74873793  0.22421275 ... -1.4233725  -0.6594168\n",
        "   0.9215936 ]\n",
        " [ 3.3737018   0.6492784   1.6181757  ... -1.0296421   1.5623202\n",
        "   2.4721022 ]\n",
        " [ 1.8228011   0.492796   -1.6068188  ... -0.4117354   0.11404424\n",
        "   1.5135489 ]\n",
        " ...\n",
        " [ 2.5912807   1.0482031   1.819718   ... -1.0550615  -0.17240341\n",
        "  -1.1659586 ]\n",
        " [ 3.4460654   0.00957024  1.0006431  ... -1.4993671   0.03530868\n",
        "   0.8717873 ]\n",
        " [ 2.1276662   1.7652162  -2.193264   ... -2.1182292  -0.01087397\n",
        "  -0.46806827]]\n",
        "('c_final_dim = ', (500, 46))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('z_dim = ', (500, 6))\n",
        "[[ 2.5367048  -1.0609616   1.4067931  ... -0.5293427  -0.20135628\n",
        "   0.89137733]\n",
        " [ 2.791073   -1.2415462  -0.05771478 ... -0.61594784  0.9274087\n",
        "  -0.27472234]\n",
        " [ 3.3888485  -0.9645176   0.8510404  ... -0.968397   -0.02467307\n",
        "   1.8776628 ]\n",
        " ...\n",
        " [ 4.561099   -1.4679832   0.44563887 ... -1.0963395   0.12932469\n",
        "   0.70711124]\n",
        " [ 2.518612   -0.95121235  0.25918707 ... -1.3161719   0.7125344\n",
        "   0.73960054]\n",
        " [ 2.824845   -1.2106305   1.5174929  ...  0.32633308  1.3904655\n",
        "  -0.5966425 ]]\n",
        "('c_final_dim = ', (500, 46))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('z_dim = ', (500, 6))\n",
        "[[ 2.6850777   1.2652851   0.74942344 ... -1.7150056  -0.529819\n",
        "   0.7144799 ]\n",
        " [ 2.3361504  -0.22659978  0.9021233  ... -3.628057   -0.09402729\n",
        "   2.735734  ]\n",
        " [ 1.2771875  -0.01764582 -0.6978509  ... -1.025495   -1.264645\n",
        "   0.4204242 ]\n",
        " ...\n",
        " [ 5.1194305  -0.58876187 -0.37492082 ... -3.5977666   1.1835396\n",
        "   0.5556325 ]\n",
        " [ 3.4102542   0.50859904  1.1677592  ... -3.420382   -1.0130694\n",
        "  -0.13623728]\n",
        " [ 2.634168    1.6696995  -1.9369415  ... -1.4895086   0.17093156\n",
        "   0.27493066]]\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from visualization_msgs.msg import Marker\n",
      "from visualization_msgs.msg import MarkerArray\n",
      "import herbpy\n",
      "import os\n",
      "\n",
      "def load_herb_and_env(cond): #46 parameters (s, g, table_pos, box_pos)\n",
      "    s_conf = cond[:7]\n",
      "    g_conf = cond[7:14]\n",
      "    table_pose = cond[14:30].reshape(4,4)\n",
      "    box_pose   = cond[30:46].reshape(4,4)\n",
      "    \n",
      "    table.SetTransform(table_pose)\n",
      "    tall_white_box.SetTransform(box_pose)\n",
      "    \n",
      "    return env, robot\n",
      "\n",
      "def get_eepositions_from_samples(env, robot, samples_conf):\n",
      "    eepositions = []\n",
      "    for i in range(len(samples_conf)):\n",
      "            conf = samples_conf[i,:]\n",
      "#             print(conf)\n",
      "            robot.SetActiveDOFValues(conf)\n",
      "            ee_trans = robot.right_arm.GetEndEffectorTransform()\n",
      "            trans = ee_trans[0:3,3]\n",
      "            eepos = trans.tolist()\n",
      "            eepositions.append(eepos)\n",
      "    return eepositions\n",
      "\n",
      "def load_marker(eepositions, markerArray, c = [0.0, 0.0, 1.0]):\n",
      "    i = 0\n",
      "    for e in eepositions:\n",
      "            marker = Marker()\n",
      "            marker.header.frame_id = \"/map\"\n",
      "            marker.type = marker.SPHERE\n",
      "            marker.action = marker.ADD\n",
      "            marker.scale.x = 0.05\n",
      "            marker.scale.y = 0.05\n",
      "            marker.scale.z = 0.05\n",
      "            marker.color.a = 1.0\n",
      "            marker.color.r = c[0]\n",
      "            marker.color.g = c[1]\n",
      "            marker.color.b = c[2]\n",
      "            marker.pose.orientation.w = 1.0\n",
      "            marker.pose.position.x = e[0]\n",
      "            marker.pose.position.y = e[1] \n",
      "            marker.pose.position.z = e[2]\n",
      "            markerArray.markers.append(marker)\n",
      "            i += 1\n",
      "\n",
      "    return eepositions, markerArray\n",
      "\n",
      "def publish_samples(eepositions, s_conf, g_conf, env, robot, publisher):\n",
      "    ee_sg = get_eepositions_from_samples(env, robot, np.array([s_conf, g_conf]))\n",
      "    markerArray = MarkerArray()\n",
      "    eepositions, markerArray = load_marker(eepositions, markerArray)\n",
      "    \n",
      "    #adding start node\n",
      "    marker = Marker()\n",
      "    marker.header.frame_id = \"/map\"\n",
      "    marker.type = marker.SPHERE\n",
      "    marker.action = marker.ADD\n",
      "    marker.scale.x = 0.08\n",
      "    marker.scale.y = 0.08\n",
      "    marker.scale.z = 0.08\n",
      "    marker.color.a = 1.0\n",
      "    marker.color.r = 1\n",
      "    marker.color.g = 0\n",
      "    marker.color.b = 0\n",
      "    marker.pose.orientation.w = 1.0\n",
      "    marker.pose.position.x = ee_sg[0][0]\n",
      "    marker.pose.position.y = ee_sg[0][1] \n",
      "    marker.pose.position.z = ee_sg[0][2]\n",
      "    markerArray.markers.append(marker)\n",
      "    \n",
      "    #adding goal node\n",
      "    marker = Marker()\n",
      "    marker.header.frame_id = \"/map\"\n",
      "    marker.type = marker.SPHERE\n",
      "    marker.action = marker.ADD\n",
      "    marker.scale.x = 0.08\n",
      "    marker.scale.y = 0.08\n",
      "    marker.scale.z = 0.08\n",
      "    marker.color.a = 1.0\n",
      "    marker.color.r = 0\n",
      "    marker.color.g = 1\n",
      "    marker.color.b = 0\n",
      "    marker.pose.orientation.w = 1.0\n",
      "    marker.pose.position.x = ee_sg[1][0]\n",
      "    marker.pose.position.y = ee_sg[1][1] \n",
      "    marker.pose.position.z = ee_sg[1][2]\n",
      "    markerArray.markers.append(marker)\n",
      "    \n",
      "    id = 0\n",
      "    for m in markerArray.markers:\n",
      "           m.id = id\n",
      "           id += 1\n",
      "    publisher.publish(markerArray)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rospy.init_node('output_node_pos')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_output_samples(cond, num_viz):\n",
      "    c_sample_seed = cond\n",
      "    c_sample = np.repeat([c_sample_seed],num_viz,axis=0)\n",
      "    y_viz, z_viz = sess.run([y, z], feed_dict={z: np.random.randn(num_viz, z_dim), c: c_sample})\n",
      "    \n",
      "    return y_viz\n",
      "\n",
      "cond = c_test[2,:]\n",
      "num_viz = 3\n",
      "env, robot = load_herb_and_env(cond)\n",
      "\n",
      "output_samples = np.array(get_output_samples(cond, num_viz))\n",
      "\n",
      "robot.SetActiveDOFValues([0,0,1,1,1,1,1])\n",
      "robot.SetActiveDOFValues(output_samples[0,:])\n",
      "\n",
      "print(type(output_samples))\n",
      "\n",
      "eepositions = get_eepositions_from_samples(env, robot, output_samples)\n",
      "topic = 'output_node_pos'\n",
      "publisher = rospy.Publisher(topic, MarkerArray)\n",
      "while not rospy.is_shutdown():\n",
      "        publish_samples(eepositions, cond[:7], cond[7:14], env, robot, publisher)\n",
      "#         print(\"published\")\n",
      "        rospy.sleep(0.1)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}