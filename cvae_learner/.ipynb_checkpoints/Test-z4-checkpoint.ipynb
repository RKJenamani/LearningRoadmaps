{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Workspace problem with several narrow gaps\n",
      "\n",
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.patches as patches\n",
      "import matplotlib.gridspec as gridspec\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "import os\n",
      "import csv\n",
      "from random import randint, random\n",
      "import time\n",
      "\n",
      "# (restrict tensorflow memory growth)\n",
      "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
      "config = tf.ConfigProto()\n",
      "config.gpu_options.allow_growth=True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# neural network parameters\n",
      "mb_size = 256\n",
      "h_Q_dim = 512\n",
      "h_P_dim = 512\n",
      "\n",
      "c = 0\n",
      "# learning rate\n",
      "lr = 1e-4\n",
      "\n",
      "# problem dimensions\n",
      "dim = 7\n",
      "dataElements = dim*3 + 32 # sample (7D), init (7D), goal (7D), cond (16 + 16 (table + box) points) //total = 53\n",
      "\n",
      "z_dim = 4 # latent\n",
      "X_dim = dim # samples\n",
      "y_dim = dim # reconstruction of the original point\n",
      "c_dim = dataElements - dim # dimension of conditioning variable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define networks\n",
      "tf.reset_default_graph()\n",
      "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
      "c = tf.placeholder(tf.float32, shape=[None, 15])\n",
      "    \n",
      "# Q\n",
      "inputs_Q = tf.concat(axis=1, values=[X,c])\n",
      "\n",
      "dense_Q1 = tf.layers.dense(inputs=inputs_Q, units=h_Q_dim, activation=tf.nn.relu)\n",
      "dropout_Q1 = tf.layers.dropout(inputs=dense_Q1, rate=0.5)\n",
      "dense_Q2 = tf.layers.dense(inputs=dropout_Q1, units=h_Q_dim, activation=tf.nn.relu)\n",
      "\n",
      "z_mu = tf.layers.dense(inputs=dense_Q2, units=z_dim) # output here is z_mu\n",
      "z_logvar = tf.layers.dense(inputs=dense_Q2, units=z_dim) # output here is z_logvar\n",
      "\n",
      "# P\n",
      "eps = tf.random_normal(shape=tf.shape(z_mu))\n",
      "z = z_mu + tf.exp(z_logvar / 2) * eps\n",
      "inputs_P = tf.concat(axis=1, values=[z,c])\n",
      "\n",
      "dense_P1 = tf.layers.dense(inputs=inputs_P, units=h_P_dim, activation=tf.nn.relu)\n",
      "dropout_P1 = tf.layers.dropout(inputs=dense_P1, rate=0.5)\n",
      "dense_P2 = tf.layers.dense(inputs=dropout_P1, units=h_P_dim, activation=tf.nn.relu)\n",
      "\n",
      "y = tf.layers.dense(inputs=dense_P2, units=X_dim) # fix to also output y\n",
      "\n",
      "# training\n",
      "########### comment in the one with 0 weight and uncomment the other ###########\n",
      "w = [[1, 1, 1, 1, 1, 1, 1]];\n",
      "# w = [[1, 1, 1, 0, 0, 0]];\n",
      "recon_loss = tf.losses.mean_squared_error(labels=X, predictions=y, weights=w)\n",
      "\n",
      "# TODO: fix loss function for angles going around\n",
      "kl_loss = 10**-4 * 2 * tf.reduce_sum(tf.exp(z_logvar) + z_mu**2 - 1. - z_logvar, 1)\n",
      "\n",
      "cvae_loss = tf.reduce_mean(kl_loss + recon_loss)\n",
      "\n",
      "train_step = tf.train.AdamOptimizer(lr).minimize(cvae_loss)\n",
      "\n",
      "sess = tf.Session(config=config)\n",
      "sess.run(tf.global_variables_initializer())\n",
      "it = 0;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "saver = tf.train.Saver()\n",
      "path_ = os.getcwd() + \"/checkpoints_z4/model.ckpt\"\n",
      "print(\"path = \",path_)\n",
      "# print(\"numTrain = \",numTrain)\n",
      "try:\n",
      "    saver.restore(sess, path_)\n",
      "    print(\"Model Restored!!\")\n",
      "except Exception as e:\n",
      "    print(\"Could not restore checkpoint!\")\n",
      "    print(e)\n",
      "print(c,z)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('path = ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z4/model.ckpt')\n",
        "Could not restore checkpoint!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Assign requires shapes of both tensors to match. lhs shape= [22,512] rhs shape= [53,512]\n",
        "\t [[Node: save/Assign_5 = Assign[T=DT_FLOAT, _class=[\"loc:@dense/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense/kernel, save/RestoreV2:5)]]\n",
        "\n",
        "Caused by op u'save/Assign_5', defined at:\n",
        "  File \"<string>\", line 1, in <module>\n",
        "  File \"/usr/lib/python2.7/dist-packages/IPython/kernel/zmq/kernelapp.py\", line 468, in main\n",
        "    app.start()\n",
        "  File \"/usr/lib/python2.7/dist-packages/IPython/kernel/zmq/kernelapp.py\", line 458, in start\n",
        "    ioloop.IOLoop.instance().start()\n",
        "  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 160, in start\n",
        "    super(ZMQIOLoop, self).start()\n",
        "  File \"/usr/lib/python2.7/dist-packages/tornado/ioloop.py\", line 672, in start\n",
        "    self._handlers[fd](fd, events)\n",
        "  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 302, in wrapped\n",
        "    ret = fn(*args, **kwargs)\n",
        "  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n",
        "    self._handle_recv()\n",
        "  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n",
        "    self._run_callback(callback, msg)\n",
        "  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n",
        "    callback(*args, **kwargs)\n",
        "  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 302, in wrapped\n",
        "    ret = fn(*args, **kwargs)\n",
        "  File \"/usr/lib/python2.7/dist-packages/IPython/kernel/zmq/ipkernel.py\", line 279, in dispatcher\n",
        "    return self.dispatch_shell(stream, msg)\n",
        "  File \"/usr/lib/python2.7/dist-packages/IPython/kernel/zmq/ipkernel.py\", line 247, in dispatch_shell\n",
        "    handler(stream, idents, msg)\n",
        "  File \"/usr/lib/python2.7/dist-packages/IPython/kernel/zmq/ipkernel.py\", line 396, in execute_request\n",
        "    shell.run_cell(code, store_history=store_history, silent=silent)\n",
        "  File \"/usr/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2660, in run_cell\n",
        "    interactivity=interactivity, compiler=compiler)\n",
        "  File \"/usr/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2764, in run_ast_nodes\n",
        "    if self.run_code(code):\n",
        "  File \"/usr/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2820, in run_code\n",
        "    exec code_obj in self.user_global_ns, self.user_ns\n",
        "  File \"<ipython-input-18-102fb8923fea>\", line 1, in <module>\n",
        "    saver = tf.train.Saver()\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1338, in __init__\n",
        "    self.build()\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1347, in build\n",
        "    self._build(self._filename, build_save=True, build_restore=True)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1384, in _build\n",
        "    build_save=build_save, build_restore=build_restore)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 835, in _build_internal\n",
        "    restore_sequentially, reshape)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 494, in _AddRestoreOps\n",
        "    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 185, in restore\n",
        "    self.op.get_shape().is_fully_defined())\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py\", line 283, in assign\n",
        "    validate_shape=validate_shape)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 60, in assign\n",
        "    use_locking=use_locking, name=name)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
        "    op_def=op_def)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n",
        "    op_def=op_def)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n",
        "    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n",
        "\n",
        "InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [22,512] rhs shape= [53,512]\n",
        "\t [[Node: save/Assign_5 = Assign[T=DT_FLOAT, _class=[\"loc:@dense/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense/kernel, save/RestoreV2:5)]]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(<tf.Tensor 'Placeholder_1:0' shape=(?, 15) dtype=float32>, <tf.Tensor 'add:0' shape=(?, 4) dtype=float32>)\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create test_conditions from data dir\n",
      "print(c,z)\n",
      "def create_samples(G, directory):\n",
      "    start = np.loadtxt(directory+\"/start_node.txt\")\n",
      "    goal = np.loadtxt(directory+\"/goal_node.txt\")\n",
      "    cond = np.loadtxt(directory+\"/conditions.txt\")\n",
      "    cond = np.array([cond[23]])\n",
      "    def state_to_numpy(state):\n",
      "        strlist = state.split()\n",
      "        val_list = [float(s) for s in strlist]\n",
      "        return np.array(val_list)\n",
      "    \n",
      "    # cond = cond.split(\",\")\n",
      "    path_nodes = []\n",
      "    i = 0\n",
      "    c_samples = []\n",
      "    with open(directory + \"/path_nodes.txt\", 'r') as file:\n",
      "        lines  = file.readlines()\n",
      "        for line in lines:\n",
      "            line = line.strip('\\n')\n",
      "#             print(line)\n",
      "#             print(\"\\n\\n\")\n",
      "            if(not line == '-1'):\n",
      "                s = state_to_numpy(G.node[str(int(start[i]))]['state'])\n",
      "                g = state_to_numpy(G.node[str(int(goal[i]))]['state'])\n",
      "                path_nodes = str(line).split(\",\")\n",
      "                # print(path_nodes)\n",
      "                for path_node in path_nodes:\n",
      "                    node_conf = state_to_numpy(G.node[path_node]['state'])\n",
      "                    curr_node = np.array([])\n",
      "                    # print(\"Data = \",node_conf, s, g, cond)\n",
      "#                     print(\"\\n\")\n",
      "                    curr_node = np.concatenate((s, g, cond))\n",
      "                    c_samples.append(curr_node)\n",
      "    return np.array(c_samples)\n",
      "print(\"c, z = \",c, z)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(<tf.Tensor 'Placeholder_1:0' shape=(?, 15) dtype=float32>, <tf.Tensor 'add:0' shape=(?, 6) dtype=float32>)\n",
        "('c, z = ', <tf.Tensor 'Placeholder_1:0' shape=(?, 15) dtype=float32>, <tf.Tensor 'add:0' shape=(?, 6) dtype=float32>)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_viz = 300\n",
      "c_final = []\n",
      "print(\"c, z = \", c, z)\n",
      "import networkx as nx\n",
      "from random import choice\n",
      "G = nx.read_graphml(\"graphs/modified_graph_30000.graphml\")\n",
      "\n",
      "dire = [\"test_data_9June/T1/2\", \"test_data_9June/T1/4\", \"test_data_9June/T2/2\", \"test_data_9June/T2/4\", \"test_data_9June/T2/10\", \"test_data_9June/T2/12\"]\n",
      "dire = [\"test_data_9June/T2/14\"]\n",
      "\n",
      "for directory in dire:\n",
      "    c_final = []\n",
      "    c_samples = np.float32(create_samples(G, directory))\n",
      "\n",
      "    for i in range(num_viz):\n",
      "        c_final.append(choice(c_samples))\n",
      "    z_final = np.random.randn(num_viz,z_dim)\n",
      "\n",
      "    c_final = np.array(c_final)\n",
      "    print(\"c_final_dim = \",c_final.shape)\n",
      "    print(\"z_dim = \",z_final.shape)\n",
      "    # directly sample from the latent space (preferred, what we will use in the end)\n",
      "    y_viz, z_viz = sess.run([y, z], feed_dict={z: z_final, c: c_final})\n",
      "\n",
      "    print(y_viz)\n",
      "    np.savetxt(directory+\"/output_samples_\"+str(z_dim)+\".txt\", y_viz, delimiter=\" \", fmt=\"%s\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('c, z = ', <tf.Tensor 'Placeholder_1:0' shape=(?, 15) dtype=float32>, <tf.Tensor 'add:0' shape=(?, 6) dtype=float32>)\n",
        "('c_final_dim = ', (300, 15))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('z_dim = ', (300, 6))\n",
        "[[-0.13126904  0.2016623   0.50899243 ...  0.3251601  -0.19834146\n",
        "  -0.36544695]\n",
        " [-0.03767772  0.2833392   0.6723428  ...  0.4175379  -0.13529414\n",
        "  -0.45354557]\n",
        " [ 0.0922575   0.26533288  0.5029856  ...  0.38143235 -0.1029078\n",
        "  -0.19190119]\n",
        " ...\n",
        " [ 0.06183108  0.41920787  0.48847708 ...  0.4380325  -0.09322815\n",
        "  -0.518976  ]\n",
        " [ 0.07012317  0.3230964   0.5473769  ...  0.33979452 -0.07772915\n",
        "  -0.41848356]\n",
        " [ 0.11496693  0.37451988  0.54289246 ...  0.3615855  -0.04740354\n",
        "  -0.39257598]]\n"
       ]
      }
     ],
     "prompt_number": 11
    }
   ],
   "metadata": {}
  }
 ]
}