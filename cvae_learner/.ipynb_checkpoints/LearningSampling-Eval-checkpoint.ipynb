{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workspace problem with several narrow gaps\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "import csv\n",
    "from random import randint, random\n",
    "import time\n",
    "\n",
    "# (restrict tensorflow memory growth)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network parameters\n",
    "mb_size = 256\n",
    "h_Q_dim = 512\n",
    "h_P_dim = 512\n",
    "\n",
    "c = 0\n",
    "# learning rate\n",
    "lr = 1e-4\n",
    "\n",
    "# problem dimensions\n",
    "dim = 7\n",
    "dataElements = dim*3 + 16 # sample (7D), init (7D), goal (7D), cond (16 points) //total = 37\n",
    "\n",
    "z_dim = 3 # latent\n",
    "X_dim = dim # samples\n",
    "y_dim = dim # reconstruction of the original point\n",
    "c_dim = dataElements - dim # dimension of conditioning variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define networks\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
    "c = tf.placeholder(tf.float32, shape=[None, 30])\n",
    "    \n",
    "# Q\n",
    "inputs_Q = tf.concat(axis=1, values=[X,c])\n",
    "\n",
    "dense_Q1 = tf.layers.dense(inputs=inputs_Q, units=h_Q_dim, activation=tf.nn.relu)\n",
    "dropout_Q1 = tf.layers.dropout(inputs=dense_Q1, rate=0.5)\n",
    "dense_Q2 = tf.layers.dense(inputs=dropout_Q1, units=h_Q_dim, activation=tf.nn.relu)\n",
    "\n",
    "z_mu = tf.layers.dense(inputs=dense_Q2, units=z_dim) # output here is z_mu\n",
    "z_logvar = tf.layers.dense(inputs=dense_Q2, units=z_dim) # output here is z_logvar\n",
    "\n",
    "# P\n",
    "eps = tf.random_normal(shape=tf.shape(z_mu))\n",
    "z = z_mu + tf.exp(z_logvar / 2) * eps\n",
    "inputs_P = tf.concat(axis=1, values=[z,c])\n",
    "\n",
    "dense_P1 = tf.layers.dense(inputs=inputs_P, units=h_P_dim, activation=tf.nn.relu)\n",
    "dropout_P1 = tf.layers.dropout(inputs=dense_P1, rate=0.5)\n",
    "dense_P2 = tf.layers.dense(inputs=dropout_P1, units=h_P_dim, activation=tf.nn.relu)\n",
    "\n",
    "y = tf.layers.dense(inputs=dense_P2, units=X_dim) # fix to also output y\n",
    "\n",
    "# training\n",
    "########### comment in the one with 0 weight and uncomment the other ###########\n",
    "w = [[1, 1, 1, 1, 1, 1, 1]];\n",
    "# w = [[1, 1, 1, 0, 0, 0]];\n",
    "recon_loss = tf.losses.mean_squared_error(labels=X, predictions=y, weights=w)\n",
    "\n",
    "# TODO: fix loss function for angles going around\n",
    "kl_loss = 10**-4 * 2 * tf.reduce_sum(tf.exp(z_logvar) + z_mu**2 - 1. - z_logvar, 1)\n",
    "\n",
    "cvae_loss = tf.reduce_mean(kl_loss + recon_loss)\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(cvae_loss)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "it = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('path = ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_withoutV/model.ckpt')\n",
      "INFO:tensorflow:Restoring parameters from /home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_withoutV/model.ckpt\n",
      "Model Restored!!\n",
      "(<tf.Tensor 'Placeholder_1:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'add:0' shape=(?, 3) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "path_ = os.getcwd() + \"/checkpoints_withoutV/model.ckpt\"\n",
    "print(\"path = \",path_)\n",
    "# print(\"numTrain = \",numTrain)\n",
    "try:\n",
    "    saver.restore(sess, path_)\n",
    "    print(\"Model Restored!!\")\n",
    "except Exception as e:\n",
    "    print(\"Could not restore checkpoint!\")\n",
    "    print(e)\n",
    "print(c,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'Placeholder_1:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'add:0' shape=(?, 3) dtype=float32>)\n",
      "('c, z = ', <tf.Tensor 'Placeholder_1:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'add:0' shape=(?, 3) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "# create test_conditions from data dir\n",
    "print(c,z)\n",
    "def create_samples(G, directory):\n",
    "    start = np.loadtxt(directory+\"/start_node.txt\")\n",
    "    goal = np.loadtxt(directory+\"/goal_node.txt\")\n",
    "    cond = np.loadtxt(directory+\"/conditions.txt\")\n",
    "    def state_to_numpy(state):\n",
    "        strlist = state.split()\n",
    "        val_list = [float(s) for s in strlist]\n",
    "        return np.array(val_list)\n",
    "    \n",
    "    # cond = cond.split(\",\")\n",
    "    path_nodes = []\n",
    "    i = 0\n",
    "    c_samples = []\n",
    "    with open(directory + \"/path_nodes.txt\", 'r') as file:\n",
    "        lines  = file.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip('\\n')\n",
    "#             print(line)\n",
    "#             print(\"\\n\\n\")\n",
    "            if(not line == '-1'):\n",
    "                s = state_to_numpy(G.node[str(int(start[i]))]['state'])\n",
    "                g = state_to_numpy(G.node[str(int(goal[i]))]['state'])\n",
    "                path_nodes = str(line).split(\",\")\n",
    "                # print(path_nodes)\n",
    "                for path_node in path_nodes:\n",
    "                    node_conf = state_to_numpy(G.node[path_node]['state'])\n",
    "                    curr_node = np.array([])\n",
    "                    # print(\"Data = \",node_conf, s, g, cond)\n",
    "#                     print(\"\\n\")\n",
    "                    curr_node = np.concatenate((s, g, cond))\n",
    "                    c_samples.append(curr_node)\n",
    "    return np.array(c_samples)\n",
    "print(\"c, z = \",c, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('c, z = ', <tf.Tensor 'Placeholder_1:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'add:0' shape=(?, 3) dtype=float32>)\n",
      "('c_final_dim = ', (300, 30))\n",
      "('z_dim = ', (300, 3))\n",
      "[[ 0.43628395  0.38591212  0.49438584 ... -0.19077803 -0.09320689\n",
      "  -0.16677204]\n",
      " [ 0.5497852   0.35691768  0.4321581  ... -0.24812225 -0.18275273\n",
      "  -0.34329066]\n",
      " [ 0.19762583  0.07513419  0.61250186 ... -0.46197957 -0.01677142\n",
      "  -0.13967901]\n",
      " ...\n",
      " [ 0.34114513  0.2527061   0.54103637 ... -0.32293212 -0.06976452\n",
      "  -0.1982525 ]\n",
      " [ 0.3852682   0.42798984  0.5537027  ... -0.2853732  -0.08765384\n",
      "  -0.10081662]\n",
      " [ 0.4307012   0.37130237  0.48860377 ... -0.21636654 -0.09689958\n",
      "  -0.18370825]]\n"
     ]
    }
   ],
   "source": [
    "num_viz = 300\n",
    "c_final = []\n",
    "print(\"c, z = \", c, z)\n",
    "import networkx as nx\n",
    "from random import choice\n",
    "G = nx.read_graphml(\"graphs/herb_halton_1.graphml\")\n",
    "directory = \"data/T1/9\"\n",
    "c_samples = np.float32(create_samples(G, directory))\n",
    "\n",
    "for i in range(num_viz):\n",
    "    c_final.append(choice(c_samples))\n",
    "z_final = np.random.randn(num_viz,z_dim)\n",
    "\n",
    "c_final = np.array(c_final)\n",
    "print(\"c_final_dim = \",c_final.shape)\n",
    "print(\"z_dim = \",z_final.shape)\n",
    "# directly sample from the latent space (preferred, what we will use in the end)\n",
    "y_viz, z_viz = sess.run([y, z], feed_dict={z: z_final, c: c_final})\n",
    "\n",
    "print(y_viz)\n",
    "np.savetxt(\"output_samples.txt\", start_node, delimiter=\" \", fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
