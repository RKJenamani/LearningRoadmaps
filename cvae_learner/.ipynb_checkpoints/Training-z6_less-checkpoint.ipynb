{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import openravepy\n",
      "import rospy\n",
      "import os\n",
      "import herbpy\n",
      "from prpy import serialization\n",
      "\n",
      "env, robot = herbpy.initialize(sim=True, attach_viewer='interactivemarker')\n",
      "\n",
      "from catkin.find_in_workspaces import find_in_workspaces\n",
      "\n",
      "package_name = 'pr_ordata'\n",
      "directory = 'data'\n",
      "objects_path = find_in_workspaces(\n",
      "    search_dirs=['share'],\n",
      "    project=package_name,\n",
      "    path=directory,\n",
      "    first_match_only=True)\n",
      "if len(objects_path) == 0:\n",
      "    print('Can\\'t find directory %s/%s' % (package_name, directory))\n",
      "    sys.exit()\n",
      "else:\n",
      "    print objects_path # for me this is '/home/USERNAME/catkin_workspaces/herb_ws/src/pr-ordata/data/objects'\n",
      "    objects_path = objects_path[0]\n",
      "    \n",
      "robot.right_arm.SetActive()\n",
      "# Load table from pr_ordata\n",
      "table_file = os.path.join(objects_path,'objects/table.kinbody.xml')\n",
      "tall_white_box_file = os.path.join(objects_path,'objects/tall_white_box.kinbody.xml')\n",
      "table = env.ReadKinBodyXMLFile(table_file)\n",
      "env.AddKinBody(table)\n",
      "tall_white_box = env.ReadKinBodyXMLFile(tall_white_box_file)\n",
      "env.AddKinBody(tall_white_box)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[INFO] [prpy.controllers.trigger_controller:trigger_controller.py:21]:__init__: Trigger Controller initialized\u001b[0m\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[INFO] [prpy.controllers.trigger_controller:trigger_controller.py:21]:__init__: Trigger Controller initialized\u001b[0m\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['/home/vernwalrahul/projects/catkin_ws/src/pr_ordata/data']\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Workspace problem with several narrow gaps\n",
      "\n",
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.patches as patches\n",
      "import matplotlib.gridspec as gridspec\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "import os\n",
      "import csv\n",
      "from random import randint, random\n",
      "import time\n",
      "\n",
      "# (restrict tensorflow memory growth)\n",
      "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
      "config = tf.ConfigProto()\n",
      "config.gpu_options.allow_growth=True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python2.7/pkgutil.py:186: ImportWarning: Not importing directory '/usr/local/lib/python2.7/dist-packages/virtualenvwrapper': missing __init__.py\n",
        "  file, filename, etc = imp.find_module(subname, path)\n",
        "/usr/lib/python2.7/pkgutil.py:186: ImportWarning: Not importing directory '/usr/local/lib/python2.7/dist-packages/google': missing __init__.py\n",
        "  file, filename, etc = imp.find_module(subname, path)\n",
        "/usr/lib/python2.7/dist-packages/scipy/ndimage/measurements.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility\n",
        "  from . import _ni_label\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# neural network parameters\n",
      "mb_size = 256\n",
      "h_Q_dim = 512\n",
      "h_P_dim = 512\n",
      "\n",
      "c = 0\n",
      "# learning rate\n",
      "lr = 1e-4\n",
      "\n",
      "# problem dimensions\n",
      "dim = 7\n",
      "dataElements = dim*3 + 32 # sample (7D), init (7D), goal (7D), cond (16+16 points (table + box)) //total = 37\n",
      "\n",
      "z_dim = 6 # latent\n",
      "X_dim = dim # samples\n",
      "y_dim = dim # reconstruction of the original point\n",
      "c_dim = dataElements - dim # dimension of conditioning variable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read in data from csv\n",
      "filename = 'samplingdata.txt'\n",
      "f = open(filename, 'rb')\n",
      "reader = csv.reader(f, delimiter=',')\n",
      "count = 0\n",
      "data_list = []\n",
      "for row in reader:\n",
      "    data_list.append(map(float,row[0:dataElements]))\n",
      "\n",
      "data = np.array(data_list,dtype='d')\n",
      "\n",
      "######################### Comment it #############\n",
      "# data[:,3:6] = 0\n",
      "##################################################\n",
      "print(\"shape of array: \",data.shape)\n",
      "\n",
      "numEntries = data.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('shape of array: ', (12716, 53))\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# split the inputs and conditions into test train (to be processed in the next step into an occupancy grid representation)\n",
      "ratioTestTrain = 0.4;\n",
      "numTrain = int(numEntries*ratioTestTrain)\n",
      "\n",
      "X_train = data[0:numTrain,0:dim] # state: x, y, z, xdot, ydot, zdot\n",
      "c_train = data[0:numTrain,dim:dataElements] # conditions: gaps, init (6), goal (6)\n",
      "\n",
      "X_test = data[numTrain:numEntries,0:dim]\n",
      "c_test = data[numTrain:numEntries,dim:dataElements]\n",
      "\n",
      "#########################################################\n",
      "c_train1 = []\n",
      "c_test1 = []\n",
      "c_train1 = c_train\n",
      "c_test1 = c_test\n",
      "#########################################################\n",
      "numTest = X_test.shape[0]\n",
      "\n",
      "# print(\"shape of final obstacle = \",obs.shape)\n",
      "print(\"shape of c_train1 = \", c_train1.shape)\n",
      "print(\"shape of c_test1 = \",c_test1.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('shape of c_train1 = ', (5086, 46))\n",
        "('shape of c_test1 = ', (7630, 46))\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define networks\n",
      "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
      "c = tf.placeholder(tf.float32, shape=[None, c_dim])\n",
      "\n",
      "# Q\n",
      "inputs_Q = tf.concat(axis=1, values=[X,c])\n",
      "\n",
      "dense_Q1 = tf.layers.dense(inputs=inputs_Q, units=h_Q_dim, activation=tf.nn.relu)\n",
      "dropout_Q1 = tf.layers.dropout(inputs=dense_Q1, rate=0.5)\n",
      "dense_Q2 = tf.layers.dense(inputs=dropout_Q1, units=h_Q_dim, activation=tf.nn.relu)\n",
      "\n",
      "z_mu = tf.layers.dense(inputs=dense_Q2, units=z_dim) # output here is z_mu\n",
      "z_logvar = tf.layers.dense(inputs=dense_Q2, units=z_dim) # output here is z_logvar\n",
      "\n",
      "# P\n",
      "eps = tf.random_normal(shape=tf.shape(z_mu))\n",
      "z = z_mu + tf.exp(z_logvar / 2) * eps\n",
      "# z_sigma = tf.exp(z_logvar /2)\n",
      "inputs_P = tf.concat(axis=1, values=[z,c])\n",
      "\n",
      "dense_P1 = tf.layers.dense(inputs=inputs_P, units=h_P_dim, activation=tf.nn.relu)\n",
      "dropout_P1 = tf.layers.dropout(inputs=dense_P1, rate=0.5)\n",
      "dense_P2 = tf.layers.dense(inputs=dropout_P1, units=h_P_dim, activation=tf.nn.relu)\n",
      "\n",
      "y = tf.layers.dense(inputs=dense_P2, units=X_dim) # fix to also output y\n",
      "\n",
      "# training\n",
      "########### comment in the one with 0 weight and uncomment the other ###########\n",
      "w = [[1, 1, 1, 1, 1, 1, 1]];\n",
      "# w = [[1, 1, 1, 0, 0, 0]];\n",
      "recon_loss = tf.losses.mean_squared_error(labels=X, predictions=y, weights=w)\n",
      "\n",
      "# TODO: fix loss function for angles going around\n",
      "kl_loss = 10**-4 * 2 * tf.reduce_sum(tf.exp(z_logvar) + z_mu**2 - 1. - z_logvar, 1)\n",
      "\n",
      "cvae_loss = tf.reduce_mean(kl_loss + recon_loss)\n",
      "\n",
      "train_step = tf.train.AdamOptimizer(lr).minimize(cvae_loss)\n",
      "\n",
      "sess = tf.Session(config=config)\n",
      "sess.run(tf.global_variables_initializer())\n",
      "it = 0;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "saver = tf.train.Saver()\n",
      "path_ = os.getcwd() + \"/checkpoints_z6_11Junedata_less/model.ckpt\"\n",
      "print(\"path = \",path_)\n",
      "print(\"numTrain = \",numTrain)\n",
      "try:\n",
      "    saver.restore(sess, path_)\n",
      "    print(\"Model Restored!!\")\n",
      "except Exception as e:\n",
      "    print(\"Could not restore checkpoint!\")\n",
      "    print(e)\n",
      "x1 = []\n",
      "y1 = []    \n",
      "mu = []\n",
      "sigma = []\n",
      "n_ = []\n",
      "for it in range(it,it+500001):\n",
      "    # randomly generate batches\n",
      "    batch_elements = [randint(0,numTrain-1) for n in range(0,mb_size)]\n",
      "    X_mb = X_train[batch_elements,:]\n",
      "    c_mb = c_train1[batch_elements,:]\n",
      "    \n",
      "    _, loss, r = sess.run([train_step, cvae_loss, recon_loss], feed_dict={X: X_mb, c: c_mb})\n",
      "\n",
      "#     _, loss, m, s = sess.run([train_step, cvae_loss, z_mu, z_sigma], feed_dict={X: X_mb, c: c_mb})\n",
      "\n",
      "    if it % 1000 == 0:\n",
      "        print('Iter: {}'.format(it))\n",
      "        print('Loss: {:.7}'. format(loss))\n",
      "        print('Recon_Loss: {:.7}'.format(r))\n",
      "        print(\"kl_loss = \", loss-r)\n",
      "#         mu.append(m)\n",
      "#         sigma.append(s)\n",
      "        n_.append(it)\n",
      "        saver.save(sess, path_)\n",
      "        print(\"saved session to \", path_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('path = ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_less/model.ckpt')\n",
        "('numTrain = ', 5086)\n",
        "[INFO] [tensorflow:tf_logging.py:116]:info: Restoring parameters from /home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_less/model.ckpt\u001b[0m\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Model Restored!!\n",
        "Iter: 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.01014758\n",
        "Recon_Loss: 0.001731789\n",
        "('kl_loss = ', 0.008415795)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.01008988\n",
        "Recon_Loss: 0.001639473\n",
        "('kl_loss = ', 0.008450402)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 2000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.009850325\n",
        "Recon_Loss: 0.001500636\n",
        "('kl_loss = ', 0.00834969)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 3000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.009908793\n",
        "Recon_Loss: 0.001573474\n",
        "('kl_loss = ', 0.008335318)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 4000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.01013359\n",
        "Recon_Loss: 0.001680399\n",
        "('kl_loss = ', 0.008453195)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 5000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.01009453\n",
        "Recon_Loss: 0.001692588\n",
        "('kl_loss = ', 0.008401939)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 6000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.009739748\n",
        "Recon_Loss: 0.00137207\n",
        "('kl_loss = ', 0.008367678)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 7000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.00991048\n",
        "Recon_Loss: 0.001474198\n",
        "('kl_loss = ', 0.008436282)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 8000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.009946683\n",
        "Recon_Loss: 0.0015441\n",
        "('kl_loss = ', 0.008402583)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 9000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.00996971\n",
        "Recon_Loss: 0.001618082\n",
        "('kl_loss = ', 0.008351629)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 10000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.00988437\n",
        "Recon_Loss: 0.001460066\n",
        "('kl_loss = ', 0.008424304)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 11000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.01006939\n",
        "Recon_Loss: 0.001684339\n",
        "('kl_loss = ', 0.008385052)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 12000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.01007374\n",
        "Recon_Loss: 0.001744151\n",
        "('kl_loss = ', 0.008329592)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 13000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.01021012\n",
        "Recon_Loss: 0.001861612\n",
        "('kl_loss = ', 0.008348505)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_less/model.ckpt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter: 14000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss: 0.01016176\n",
        "Recon_Loss: 0.001751733\n",
        "('kl_loss = ', 0.008410028)\n",
        "('saved session to ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_z6_11Junedata_less/model.ckpt')"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-7-7e86f06fa834>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mc_mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_train1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_elements\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcvae_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc_mb\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#     _, loss, m, s = sess.run([train_step, cvae_loss, z_mu, z_sigma], feed_dict={X: X_mb, c: c_mb})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(c,z)\n",
      "def create_samples(G, directory):\n",
      "    start = np.loadtxt(directory+\"/start_node.txt\")\n",
      "    goal = np.loadtxt(directory+\"/goal_node.txt\")\n",
      "    cond = np.loadtxt(directory+\"/conditions.txt\")\n",
      "#     cond = np.array([cond[23]])\n",
      "    def state_to_numpy(state):\n",
      "        strlist = state.split()\n",
      "        val_list = [float(s) for s in strlist]\n",
      "        return np.array(val_list)\n",
      "    \n",
      "    # cond = cond.split(\",\")\n",
      "    path_nodes = []\n",
      "    i = 0\n",
      "    c_samples = []\n",
      "    with open(directory + \"/path_nodes.txt\", 'r') as file:\n",
      "        lines  = file.readlines()\n",
      "        for line in lines:\n",
      "            line = line.strip('\\n')\n",
      "#             print(line)\n",
      "#             print(\"\\n\\n\")\n",
      "            if(not line == '-1'):\n",
      "                s = state_to_numpy(G.node[str(int(start[i]))]['state'])\n",
      "                g = state_to_numpy(G.node[str(int(goal[i]))]['state'])\n",
      "                path_nodes = str(line).split(\",\")\n",
      "                # print(path_nodes)\n",
      "                for path_node in path_nodes:\n",
      "                    node_conf = state_to_numpy(G.node[path_node]['state'])\n",
      "                    curr_node = np.array([])\n",
      "                    # print(\"Data = \",node_conf, s, g, cond)\n",
      "#                     print(\"\\n\")\n",
      "                    curr_node = np.concatenate((s, g, cond))\n",
      "                    c_samples.append(curr_node)\n",
      "    return np.array(c_samples)\n",
      "print(\"c, z = \",c, z)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(<tf.Tensor 'Placeholder_1:0' shape=(?, 46) dtype=float32>, <tf.Tensor 'add:0' shape=(?, 6) dtype=float32>)\n",
        "('c, z = ', <tf.Tensor 'Placeholder_1:0' shape=(?, 46) dtype=float32>, <tf.Tensor 'add:0' shape=(?, 6) dtype=float32>)\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_v = [200, 300, 400, 500]\n",
      "c_final = []\n",
      "print(\"c, z = \", c, z)\n",
      "import networkx as nx\n",
      "from random import choice\n",
      "G = nx.read_graphml(\"graphs/modified_graph_30000.graphml\")\n",
      "\n",
      "dire = [\"test_data_11June/T1/4\", \"test_data_11June/T1/7\", \"test_data_11June/T2/0\", \"test_data_11June/T2/4\", \"test_data_11June/T2/7\", \"test_data_11June/T2/14\"]\n",
      "# dire = [\"temp_data/T2/5\", \"temp_data/T1/5\"]\n",
      "for num_viz in num_v:\n",
      "    for directory in dire:\n",
      "        c_final = []\n",
      "        c_samples = np.float32(create_samples(G, directory))\n",
      "    \n",
      "        for i in range(num_viz):\n",
      "            c_final.append(choice(c_samples))\n",
      "        z_final = np.random.randn(num_viz,z_dim)\n",
      "    \n",
      "        c_final = np.arra y(c_final)\n",
      "        print(\"c_final_dim = \",c_final.shape)\n",
      "        print(\"z_dim = \",z_final.shape)\n",
      "        # directly sample from the latent space (preferred, what we will use in the end)\n",
      "        y_viz, z_viz = sess.run([y, z], feed_dict={z: z_final, c: c_final})\n",
      "    \n",
      "        print(y_viz)\n",
      "        np.savetxt(directory+\"/output_samples_z\"+str(z_dim)+\"_n\"+str(num_viz)+\".txt\", y_viz, delimiter=\" \", fmt=\"%s\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from visualization_msgs.msg import Marker\n",
      "from visualization_msgs.msg import MarkerArray\n",
      "import herbpy\n",
      "import os\n",
      "\n",
      "def load_herb_and_env(cond): #46 parameters (s, g, table_pos, box_pos)\n",
      "    s_conf = cond[:7]\n",
      "    g_conf = cond[7:14]\n",
      "    table_pose = cond[14:30].reshape(4,4)\n",
      "    box_pose   = cond[30:46].reshape(4,4)\n",
      "    \n",
      "    table.SetTransform(table_pose)\n",
      "    tall_white_box.SetTransform(box_pose)\n",
      "    \n",
      "    return env, robot\n",
      "\n",
      "def get_eepositions_from_samples(env, robot, samples_conf):\n",
      "    eepositions = []\n",
      "    for i in range(len(samples_conf)):\n",
      "            conf = samples_conf[i,:]\n",
      "#             print(conf)\n",
      "            robot.SetActiveDOFValues(conf)\n",
      "            ee_trans = robot.right_arm.GetEndEffectorTransform()\n",
      "            trans = ee_trans[0:3,3]\n",
      "            eepos = trans.tolist()\n",
      "            eepositions.append(eepos)\n",
      "    return eepositions\n",
      "\n",
      "def load_marker(eepositions, markerArray, c = [0.0, 0.0, 1.0]):\n",
      "    i = 0\n",
      "    for e in eepositions:\n",
      "            marker = Marker()\n",
      "            marker.header.frame_id = \"/map\"\n",
      "            marker.type = marker.SPHERE\n",
      "            marker.action = marker.ADD\n",
      "            marker.scale.x = 0.05\n",
      "            marker.scale.y = 0.05\n",
      "            marker.scale.z = 0.05\n",
      "            marker.color.a = 1.0\n",
      "            marker.color.r = c[0]\n",
      "            marker.color.g = c[1]\n",
      "            marker.color.b = c[2]\n",
      "            marker.pose.orientation.w = 1.0\n",
      "            marker.pose.position.x = e[0]\n",
      "            marker.pose.position.y = e[1] \n",
      "            marker.pose.position.z = e[2]\n",
      "            markerArray.markers.append(marker)\n",
      "            i += 1\n",
      "\n",
      "    return eepositions, markerArray\n",
      "\n",
      "def publish_samples(eepositions, ee_sg, publisher):\n",
      "    ee_sg = get_eepositions_from_samples(env, robot, np.array([s_conf, g_conf]))\n",
      "    markerArray = MarkerArray()\n",
      "    eepositions, markerArray = load_marker(eepositions, markerArray)\n",
      "    \n",
      "    #adding start node\n",
      "    marker = Marker()\n",
      "    marker.header.frame_id = \"/map\"\n",
      "    marker.type = marker.SPHERE\n",
      "    marker.action = marker.ADD\n",
      "    marker.scale.x = 0.08\n",
      "    marker.scale.y = 0.08\n",
      "    marker.scale.z = 0.08\n",
      "    marker.color.a = 1.0\n",
      "    marker.color.r = 1\n",
      "    marker.color.g = 0\n",
      "    marker.color.b = 0\n",
      "    marker.pose.orientation.w = 1.0\n",
      "    marker.pose.position.x = ee_sg[0][0]\n",
      "    marker.pose.position.y = ee_sg[0][1] \n",
      "    marker.pose.position.z = ee_sg[0][2]\n",
      "    markerArray.markers.append(marker)\n",
      "    \n",
      "    #adding goal node\n",
      "    marker = Marker()\n",
      "    marker.header.frame_id = \"/map\"\n",
      "    marker.type = marker.SPHERE\n",
      "    marker.action = marker.ADD\n",
      "    marker.scale.x = 0.08\n",
      "    marker.scale.y = 0.08\n",
      "    marker.scale.z = 0.08\n",
      "    marker.color.a = 1.0\n",
      "    marker.color.r = 0\n",
      "    marker.color.g = 1\n",
      "    marker.color.b = 0\n",
      "    marker.pose.orientation.w = 1.0\n",
      "    marker.pose.position.x = ee_sg[1][0]\n",
      "    marker.pose.position.y = ee_sg[1][1] \n",
      "    marker.pose.position.z = ee_sg[1][2]\n",
      "    markerArray.markers.append(marker)\n",
      "    \n",
      "    id = 0\n",
      "    for m in markerArray.markers:\n",
      "           m.id = id\n",
      "           id += 1\n",
      "    publisher.publish(markerArray)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rospy.init_node('output_node_pos')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topic = 'output_node_pos'\n",
      "publisher = rospy.Publisher(topic, MarkerArray, queue_size=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from random import randint\n",
      "def get_output_samples(cond, num_viz):\n",
      "    c_sample_seed = cond\n",
      "    c_sample = np.repeat([c_sample_seed],num_viz,axis=0)\n",
      "    y_viz, z_viz = sess.run([y, z], feed_dict={z: np.random.randn(num_viz, z_dim), c: c_sample})\n",
      "    \n",
      "    return y_viz\n",
      "print(\"start\")\n",
      "t = 200\n",
      "cond = c_test[t,:]\n",
      "num_viz = 300\n",
      "env, robot = load_herb_and_env(cond)\n",
      "print(\"table_box added\")\n",
      "output_samples = np.array(get_output_samples(cond, num_viz))\n",
      "print(output_samples[0,:])\n",
      "\n",
      "robot.SetActiveDOFValues([0,0,1,1,1,1,1])\n",
      "robot.SetActiveDOFValues(output_samples[0,:])\n",
      "\n",
      "print(type(output_samples))\n",
      "\n",
      "eepositions = get_eepositions_from_samples(env, robot, output_samples)\n",
      "s_conf = cond[:7]\n",
      "g_conf = cond[7:14]\n",
      "ee_sg = get_eepositions_from_samples(env, robot, np.array([s_conf, g_conf]))\n",
      "\n",
      "print(\"going to publish\")\n",
      "while not rospy.is_shutdown():\n",
      "        publish_samples(eepositions, ee_sg, publisher)\n",
      "#         print(\"published\")\n",
      "        rospy.sleep(0.1)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "start\n",
        "table_box added\n",
        "[ 0.3871216  -0.72057354 -1.0777665   0.25767446 -3.2492557   1.0261432\n",
        "  1.3339146 ]\n",
        "<type 'numpy.ndarray'>\n",
        "going to publish"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-25-80b88d05d068>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"going to publish\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_shutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mpublish_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meepositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mee_sg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublisher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;31m#         print(\"published\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-9-654b0be8188c>\u001b[0m in \u001b[0;36mpublish_samples\u001b[0;34m(eepositions, ee_sg, publisher)\u001b[0m\n\u001b[1;32m     95\u001b[0m            \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m            \u001b[0mid\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mpublisher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkerArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/opt/ros/indigo/lib/python2.7/dist-packages/rospy/topics.pyc\u001b[0m in \u001b[0;36mpublish\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgenpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;31m# can't go to rospy.logerr(), b/c this could potentially recurse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/ros/indigo/lib/python2.7/dist-packages/rospy/topics.pyc\u001b[0m in \u001b[0;36mpublish\u001b[0;34m(self, message, connection_override)\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;31m# serialize the message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m#count messages published to the topic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m             \u001b[0mserialize_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0;31m# send the buffer to all connections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/ros/indigo/lib/python2.7/dist-packages/rospy/msg.pyc\u001b[0m in \u001b[0;36mserialize_message\u001b[0;34m(b, seq, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;31m#serialize the message data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROSSerializationException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/ros/indigo/lib/python2.7/dist-packages/visualization_msgs/msg/_MarkerArray.pyc\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(self, buff)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mbuff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_struct_3i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0m_v3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0m_v4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_v3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0m_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_v4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbuff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_struct_3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 25
    }
   ],
   "metadata": {}
  }
 ]
}