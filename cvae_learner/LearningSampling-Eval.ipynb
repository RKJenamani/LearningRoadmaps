{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workspace problem with several narrow gaps\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "import csv\n",
    "from random import randint, random\n",
    "import time\n",
    "\n",
    "# (restrict tensorflow memory growth)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network parameters\n",
    "mb_size = 256\n",
    "h_Q_dim = 512\n",
    "h_P_dim = 512\n",
    "\n",
    "c = 0\n",
    "# learning rate\n",
    "lr = 1e-4\n",
    "\n",
    "# problem dimensions\n",
    "dim = 7\n",
    "dataElements = dim*3 + 16 + 16 # sample (7D), init (7D), goal (7D), cond (16 + 16 (table + box) points) //total = 53\n",
    "\n",
    "z_dim = 3 # latent\n",
    "X_dim = dim # samples\n",
    "y_dim = dim # reconstruction of the original point\n",
    "c_dim = dataElements - dim # dimension of conditioning variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define networks\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
    "c = tf.placeholder(tf.float32, shape=[None, 46])\n",
    "    \n",
    "# Q\n",
    "inputs_Q = tf.concat(axis=1, values=[X,c])\n",
    "\n",
    "dense_Q1 = tf.layers.dense(inputs=inputs_Q, units=h_Q_dim, activation=tf.nn.relu)\n",
    "dropout_Q1 = tf.layers.dropout(inputs=dense_Q1, rate=0.5)\n",
    "dense_Q2 = tf.layers.dense(inputs=dropout_Q1, units=h_Q_dim, activation=tf.nn.relu)\n",
    "\n",
    "z_mu = tf.layers.dense(inputs=dense_Q2, units=z_dim) # output here is z_mu\n",
    "z_logvar = tf.layers.dense(inputs=dense_Q2, units=z_dim) # output here is z_logvar\n",
    "\n",
    "# P\n",
    "eps = tf.random_normal(shape=tf.shape(z_mu))\n",
    "z = z_mu + tf.exp(z_logvar / 2) * eps\n",
    "inputs_P = tf.concat(axis=1, values=[z,c])\n",
    "\n",
    "dense_P1 = tf.layers.dense(inputs=inputs_P, units=h_P_dim, activation=tf.nn.relu)\n",
    "dropout_P1 = tf.layers.dropout(inputs=dense_P1, rate=0.5)\n",
    "dense_P2 = tf.layers.dense(inputs=dropout_P1, units=h_P_dim, activation=tf.nn.relu)\n",
    "\n",
    "y = tf.layers.dense(inputs=dense_P2, units=X_dim) # fix to also output y\n",
    "\n",
    "# training\n",
    "########### comment in the one with 0 weight and uncomment the other ###########\n",
    "w = [[1, 1, 1, 1, 1, 1, 1]];\n",
    "# w = [[1, 1, 1, 0, 0, 0]];\n",
    "recon_loss = tf.losses.mean_squared_error(labels=X, predictions=y, weights=w)\n",
    "\n",
    "# TODO: fix loss function for angles going around\n",
    "kl_loss = 10**-4 * 2 * tf.reduce_sum(tf.exp(z_logvar) + z_mu**2 - 1. - z_logvar, 1)\n",
    "\n",
    "cvae_loss = tf.reduce_mean(kl_loss + recon_loss)\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(cvae_loss)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "it = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('path = ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_table_box/model1.ckpt')\n",
      "INFO:tensorflow:Restoring parameters from /home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints_table_box/model1.ckpt\n",
      "Model Restored!!\n",
      "(<tf.Tensor 'Placeholder_1:0' shape=(?, 46) dtype=float32>, <tf.Tensor 'add:0' shape=(?, 3) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "path_ = os.getcwd() + \"/checkpoints_table_box/model1.ckpt\"\n",
    "print(\"path = \",path_)\n",
    "# print(\"numTrain = \",numTrain)\n",
    "try:\n",
    "    saver.restore(sess, path_)\n",
    "    print(\"Model Restored!!\")\n",
    "except Exception as e:\n",
    "    print(\"Could not restore checkpoint!\")\n",
    "    print(e)\n",
    "print(c,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'Placeholder_1:0' shape=(?, 46) dtype=float32>, <tf.Tensor 'add:0' shape=(?, 3) dtype=float32>)\n",
      "('c, z = ', <tf.Tensor 'Placeholder_1:0' shape=(?, 46) dtype=float32>, <tf.Tensor 'add:0' shape=(?, 3) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "# create test_conditions from data dir\n",
    "print(c,z)\n",
    "def create_samples(G, directory):\n",
    "    start = np.loadtxt(directory+\"/start_node.txt\")\n",
    "    goal = np.loadtxt(directory+\"/goal_node.txt\")\n",
    "    cond = np.loadtxt(directory+\"/conditions.txt\")\n",
    "    def state_to_numpy(state):\n",
    "        strlist = state.split()\n",
    "        val_list = [float(s) for s in strlist]\n",
    "        return np.array(val_list)\n",
    "    \n",
    "    # cond = cond.split(\",\")\n",
    "    path_nodes = []\n",
    "    i = 0\n",
    "    c_samples = []\n",
    "    with open(directory + \"/path_nodes.txt\", 'r') as file:\n",
    "        lines  = file.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip('\\n')\n",
    "#             print(line)\n",
    "#             print(\"\\n\\n\")\n",
    "            if(not line == '-1'):\n",
    "                s = state_to_numpy(G.node[str(int(start[i]))]['state'])\n",
    "                g = state_to_numpy(G.node[str(int(goal[i]))]['state'])\n",
    "                path_nodes = str(line).split(\",\")\n",
    "                # print(path_nodes)\n",
    "                for path_node in path_nodes:\n",
    "                    node_conf = state_to_numpy(G.node[path_node]['state'])\n",
    "                    curr_node = np.array([])\n",
    "                    # print(\"Data = \",node_conf, s, g, cond)\n",
    "#                     print(\"\\n\")\n",
    "                    curr_node = np.concatenate((s, g, cond))\n",
    "                    c_samples.append(curr_node)\n",
    "    return np.array(c_samples)\n",
    "print(\"c, z = \",c, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('c, z = ', <tf.Tensor 'Placeholder_1:0' shape=(?, 46) dtype=float32>, <tf.Tensor 'add:0' shape=(?, 3) dtype=float32>)\n",
      "('c_final_dim = ', (300, 46))\n",
      "('z_dim = ', (300, 3))\n",
      "[[ 3.4728906  -0.48682195  1.8256898  ...  1.446287   -0.10137868\n",
      "  -0.02686952]\n",
      " [ 2.516064    0.83798426 -1.0701284  ... -0.2980822   1.0007374\n",
      "  -0.18996678]\n",
      " [ 5.1585383   0.5598561   2.2731428  ...  0.09126262  0.46424645\n",
      "  -1.0604553 ]\n",
      " ...\n",
      " [ 1.3808554   1.0298545   2.6271293  ... -1.1182524   0.72944415\n",
      "   0.24952783]\n",
      " [ 1.3189683   0.10047657 -0.59389186 ...  0.08661107  1.4229033\n",
      "  -1.6586992 ]\n",
      " [ 0.9692725  -0.47552127  2.2939506  ... -1.0771638   0.14892668\n",
      "  -2.0914767 ]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-05d10f6f8bd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_viz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mc_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mz_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_viz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "num_viz = 300\n",
    "c_final = []\n",
    "print(\"c, z = \", c, z)\n",
    "import networkx as nx\n",
    "from random import choice\n",
    "G = nx.read_graphml(\"graphs/modified_graph_dense.graphml\")\n",
    "\n",
    "for i in range(20):\n",
    "    env_no = str(i)\n",
    "\n",
    "    directory = \"data/T1/\" + env_no\n",
    "    c_samples = np.float32(create_samples(G, directory))\n",
    "\n",
    "    for i in range(num_viz):\n",
    "        c_final.append(choice(c_samples))\n",
    "    z_final = np.random.randn(num_viz,z_dim)\n",
    "\n",
    "    c_final = np.array(c_final)\n",
    "    print(\"c_final_dim = \",c_final.shape)\n",
    "    print(\"z_dim = \",z_final.shape)\n",
    "    # directly sample from the latent space (preferred, what we will use in the end)\n",
    "    y_viz, z_viz = sess.run([y, z], feed_dict={z: z_final, c: c_final})\n",
    "\n",
    "    print(y_viz)\n",
    "    np.savetxt(\"output_data/output_samples_\"+env_no+\".txt\", y_viz, delimiter=\" \", fmt=\"%s\")\n",
    "    np.savetxt(\"output_data/conditions_\"+env_no+\".txt\", np.loadtxt(directory+\"/conditions.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
