{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workspace problem with several narrow gaps\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "import csv\n",
    "from random import randint, random\n",
    "import time\n",
    "\n",
    "# (restrict tensorflow memory growth)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network parameters\n",
    "mb_size = 256\n",
    "h_Q_dim = 512\n",
    "h_P_dim = 512\n",
    "\n",
    "c = 0\n",
    "# learning rate\n",
    "lr = 1e-4\n",
    "\n",
    "# problem dimensions\n",
    "dim = 7\n",
    "dataElements = dim*3 + 16 # sample (7D), init (7D), goal (7D), cond (16 points) //total = 37\n",
    "\n",
    "z_dim = 3 # latent\n",
    "X_dim = dim # samples\n",
    "y_dim = dim # reconstruction of the original point\n",
    "c_dim = dataElements - dim # dimension of conditioning variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define networks\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
    "c = tf.placeholder(tf.float32, shape=[None, 30])\n",
    "    \n",
    "# Q\n",
    "inputs_Q = tf.concat(axis=1, values=[X,c])\n",
    "\n",
    "dense_Q1 = tf.layers.dense(inputs=inputs_Q, units=h_Q_dim, activation=tf.nn.relu)\n",
    "dropout_Q1 = tf.layers.dropout(inputs=dense_Q1, rate=0.5)\n",
    "dense_Q2 = tf.layers.dense(inputs=dropout_Q1, units=h_Q_dim, activation=tf.nn.relu)\n",
    "\n",
    "z_mu = tf.layers.dense(inputs=dense_Q2, units=z_dim) # output here is z_mu\n",
    "z_logvar = tf.layers.dense(inputs=dense_Q2, units=z_dim) # output here is z_logvar\n",
    "\n",
    "# P\n",
    "eps = tf.random_normal(shape=tf.shape(z_mu))\n",
    "z = z_mu + tf.exp(z_logvar / 2) * eps\n",
    "inputs_P = tf.concat(axis=1, values=[z,c])\n",
    "\n",
    "dense_P1 = tf.layers.dense(inputs=inputs_P, units=h_P_dim, activation=tf.nn.relu)\n",
    "dropout_P1 = tf.layers.dropout(inputs=dense_P1, rate=0.5)\n",
    "dense_P2 = tf.layers.dense(inputs=dropout_P1, units=h_P_dim, activation=tf.nn.relu)\n",
    "\n",
    "y = tf.layers.dense(inputs=dense_P2, units=X_dim) # fix to also output y\n",
    "\n",
    "# training\n",
    "########### comment in the one with 0 weight and uncomment the other ###########\n",
    "w = [[1, 1, 1, 1, 1, 1, 1]];\n",
    "# w = [[1, 1, 1, 0, 0, 0]];\n",
    "recon_loss = tf.losses.mean_squared_error(labels=X, predictions=y, weights=w)\n",
    "\n",
    "# TODO: fix loss function for angles going around\n",
    "kl_loss = 10**-4 * 2 * tf.reduce_sum(tf.exp(z_logvar) + z_mu**2 - 1. - z_logvar, 1)\n",
    "\n",
    "cvae_loss = tf.reduce_mean(kl_loss + recon_loss)\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(cvae_loss)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "it = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('path = ', '/home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints/model.ckpt')\n",
      "INFO:tensorflow:Restoring parameters from /home/vernwalrahul/projects/LearningRoadmaps/cvae_learner/checkpoints/model.ckpt\n",
      "Model Restored!!\n",
      "(<tf.Tensor 'Placeholder_1:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'add:0' shape=(?, 3) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "path_ = os.getcwd() + \"/checkpoints/model.ckpt\"\n",
    "print(\"path = \",path_)\n",
    "# print(\"numTrain = \",numTrain)\n",
    "try:\n",
    "    saver.restore(sess, path_)\n",
    "    print(\"Model Restored!!\")\n",
    "except Exception as e:\n",
    "    print(\"Could not restore checkpoint!\")\n",
    "    print(e)\n",
    "print(c,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'Placeholder_1:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'add:0' shape=(?, 3) dtype=float32>)\n",
      "('c, z = ', <tf.Tensor 'Placeholder_1:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'add:0' shape=(?, 3) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "# create test_conditions from data dir\n",
    "print(c,z)\n",
    "def create_samples(G, directory):\n",
    "    start = np.loadtxt(directory+\"/start_node.txt\")\n",
    "    goal = np.loadtxt(directory+\"/goal_node.txt\")\n",
    "    cond = np.loadtxt(directory+\"/conditions.txt\")\n",
    "    def state_to_numpy(state):\n",
    "        strlist = state.split()\n",
    "        val_list = [float(s) for s in strlist]\n",
    "        return np.array(val_list)\n",
    "    \n",
    "    # cond = cond.split(\",\")\n",
    "    path_nodes = []\n",
    "    i = 0\n",
    "    c_samples = []\n",
    "    with open(directory + \"/path_nodes.txt\", 'r') as file:\n",
    "        lines  = file.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip('\\n')\n",
    "#             print(line)\n",
    "#             print(\"\\n\\n\")\n",
    "            if(not line == '-1'):\n",
    "                s = state_to_numpy(G.node[str(int(start[i]))]['state'])\n",
    "                g = state_to_numpy(G.node[str(int(goal[i]))]['state'])\n",
    "                path_nodes = str(line).split(\",\")\n",
    "                # print(path_nodes)\n",
    "                for path_node in path_nodes:\n",
    "                    node_conf = state_to_numpy(G.node[path_node]['state'])\n",
    "                    curr_node = np.array([])\n",
    "                    # print(\"Data = \",node_conf, s, g, cond)\n",
    "#                     print(\"\\n\")\n",
    "                    curr_node = np.concatenate((s, g, cond))\n",
    "                    c_samples.append(curr_node)\n",
    "    return np.array(c_samples)\n",
    "print(\"c, z = \",c, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('c, z = ', <tf.Tensor 'Placeholder_1:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'add:0' shape=(?, 3) dtype=float32>)\n",
      "('c_final_dim = ', (300, 30))\n",
      "('z_dim = ', (300, 3))\n",
      "[[ 1.6873114   0.12884438  0.01461816 ... -0.6979556   0.7861268\n",
      "  -0.4043346 ]\n",
      " [ 2.5227525   0.76319945  1.0471729  ... -1.6174557   1.2124459\n",
      "   2.349605  ]\n",
      " [ 2.5710747   0.02939319 -0.54863584 ... -1.8847202  -0.45432043\n",
      "  -1.7074413 ]\n",
      " ...\n",
      " [ 2.0433564   0.4444543  -0.6867591  ... -0.23440805  0.9215563\n",
      "  -0.49700075]\n",
      " [ 2.7569654  -0.7808329   0.4577371  ... -1.7592521  -0.18151927\n",
      "  -0.5676699 ]\n",
      " [ 2.426007   -0.56831694 -0.6217632  ... -1.6227887   0.20382375\n",
      "  -1.1257238 ]]\n"
     ]
    }
   ],
   "source": [
    "num_viz = 300\n",
    "c_final = []\n",
    "print(\"c, z = \", c, z)\n",
    "import networkx as nx\n",
    "from random import choice\n",
    "G = nx.read_graphml(\"graphs/herb_halton_1.graphml\")\n",
    "directory = \"data/T1/9\"\n",
    "c_samples = np.float32(create_samples(G, directory))\n",
    "\n",
    "for i in range(num_viz):\n",
    "    c_final.append(choice(c_samples))\n",
    "z_final = np.random.randn(num_viz,z_dim)\n",
    "\n",
    "c_final = np.array(c_final)\n",
    "print(\"c_final_dim = \",c_final.shape)\n",
    "print(\"z_dim = \",z_final.shape)\n",
    "# directly sample from the latent space (preferred, what we will use in the end)\n",
    "y_viz, z_viz = sess.run([y, z], feed_dict={z: z_final, c: c_final})\n",
    "\n",
    "print(y_viz)\n",
    "np.savetxt(\"output_data/output_samples.txt\", y_viz, delimiter=\" \", fmt=\"%s\")\n",
    "np.savetxt(\"output_data/conditions.txt\", np.loadtxt(directory+\"/conditions.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
